{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd04ff0ae6d5af6cee7d4387c233617364bfe379975b0f11f74f616ffba02edc1fa",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "from typing import Any\n",
    "import sys\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import traceback\n",
    "import logging\n",
    "import numpy as np\n",
    "import warnings\n",
    "from joblib import dump, load\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "SSM_CLIENT = boto3.client(\"ssm\")\n",
    "concatenated_data_frame = pd.DataFrame()\n",
    "PARAM_NAME = \"/google/admin/credentials\"\n",
    "SCOPE = [\"https://spreadsheets.google.com/feeds\", \"https://www.googleapis.com/auth/drive\"]\n",
    "\n",
    "def get_google_credential_json():\n",
    "    response = SSM_CLIENT.get_parameters(\n",
    "        Names=[\n",
    "            PARAM_NAME,\n",
    "        ],\n",
    "        WithDecryption=True\n",
    "    )\n",
    "    return json.loads(response['Parameters'][0]['Value'])\n",
    "\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\t\"\"\"\n",
    "\tFrame a time series as a supervised learning dataset.\n",
    "\tArguments:\n",
    "\t\tdata: Sequence of observations as a list or NumPy array.\n",
    "\t\tn_in: Number of lag observations as input (X).\n",
    "\t\tn_out: Number of observations as output (y).\n",
    "\t\tdropnan: Boolean whether or not to drop rows with NaN values.\n",
    "\tReturns:\n",
    "\t\tPandas DataFrame of series framed for supervised learning.\n",
    "\t\"\"\"\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = pd.DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = pd.concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    "\n",
    "def concatenate_google_spreadsheets(google_cloud_spreadsheets):\n",
    "    index = 0\n",
    "    flag = True\n",
    "    while flag:\n",
    "        try:\n",
    "            if index:\n",
    "                worksheet = google_cloud_spreadsheets.open(f\"IFTTT_Maker_Webhooks_Events ({index})\").sheet1\n",
    "            else:\n",
    "                worksheet = google_cloud_spreadsheets.open(f\"IFTTT_Maker_Webhooks_Events\").sheet1\n",
    "        except Exception:\n",
    "            flag = False\n",
    "        else:\n",
    "            data = pd.DataFrame(worksheet.get_all_values())\n",
    "            global concatenated_data_frame\n",
    "            concatenated_data_frame = pd.concat([concatenated_data_frame, data])\n",
    "            index = index + 1\n",
    "\n",
    "\n",
    "def clean_data(duration=300, peak=75):\n",
    "    blood_glucose_dataset = concatenated_data_frame.copy()\n",
    "    blood_glucose_dataset.drop(columns=[1,3,4,5,6],axis=1,inplace=True)\n",
    "    blood_glucose_dataset.columns = [\"DATETIME\",\"BLOOD_GLUCOSE\"]\n",
    "    blood_glucose_dataset[\"BLOOD_GLUCOSE\"] = blood_glucose_dataset[\"BLOOD_GLUCOSE\"].replace([\"LOW\"], 2.2)\n",
    "    blood_glucose_dataset[\"BLOOD_GLUCOSE\"] = blood_glucose_dataset[\"BLOOD_GLUCOSE\"].replace([\"HIGH\"], 20)\n",
    "    blood_glucose_dataset[\"BLOOD_GLUCOSE\"] = blood_glucose_dataset.BLOOD_GLUCOSE.astype(\"float64\")\n",
    "    blood_glucose_dataset[\"DATETIME\"] = blood_glucose_dataset[\"DATETIME\"].str.replace('at','')\n",
    "    blood_glucose_dataset[\"DATETIME\"] = pd.to_datetime(blood_glucose_dataset[\"DATETIME\"])\n",
    "    blood_glucose_dataset.replace(r'', np.NaN, inplace=True)\n",
    "    blood_glucose_dataset.fillna(0,inplace=True)\n",
    "    blood_glucose_time_series = downsample(dataset=blood_glucose_dataset,column=\"BLOOD_GLUCOSE\", index=\"DATETIME\")\n",
    "    return blood_glucose_time_series\n",
    "\n",
    "def downsample(dataset, index, column,  period = \"30min\"):\n",
    "    dataset.set_index(index, inplace=True)\n",
    "    time_series = dataset[column].resample(period).mean()\n",
    "    return time_series\n",
    "\n",
    "\n",
    "def create_gridsearch_model(hyperparameters, x,y, regressor, scaler=RobustScaler()):\n",
    "    pipeline = make_pipeline(RobustScaler(), \n",
    "                         regressor)\n",
    "    clf = GridSearchCV(pipeline, hyperparameters, cv=3)\n",
    "    clf.fit(x, y)\n",
    "    return clf\n",
    "\n",
    "def handler(event, context):\n",
    "    credentials = ServiceAccountCredentials.from_json_keyfile_dict(get_google_credential_json())\n",
    "    google_cloud_spreadsheets = gspread.authorize(credentials)\n",
    "    concatenate_google_spreadsheets(google_cloud_spreadsheets)\n",
    "    \n",
    "    data = clean_data().reset_index()\n",
    "    data = data.BLOOD_GLUCOSE\n",
    "    data = np.array(data)\n",
    "\n",
    "\n",
    "    cleaned_dataset = series_to_supervised(data.tolist(),n_out=3)\n",
    "    random_forest_hyperparameters = {'randomforestregressor__max_depth': [1,5,10,'None'],'randomforestregressor__max_features': [1,2,3,4,5,6,7,8,9,10,11],'randomforestregressor__max_samples': [10,20,30,40,50,60,70,80,90,100], 'randomforestregressor__n_estimators': [10,50,100,1000]}\n",
    "    y = cleaned_dataset[[\"var1(t+2)\"]]\n",
    "    x = cleaned_dataset.drop([\"var1(t+2)\"],axis =1)\n",
    "    #=======================================\n",
    "    #\n",
    "    # Random forest\n",
    "    #\n",
    "    #=======================================\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "    random_forest_model = create_gridsearch_model(random_forest_hyperparameters,X_train,y_train, regressor=RandomForestRegressor())\n",
    "    random_forest_score = random_forest_model.score(X_test, y_test)\n",
    "    print(random_forest_model.best_params_)\n",
    "    dump(random_forest_model, 'rf.joblib')\n",
    "    print(\"RF\",random_forest_score)\n",
    "    #=======================================\n",
    "    #\n",
    "    # SVR\n",
    "    #\n",
    "    #=======================================\n",
    "    support_vector_regressor_hyperparameters = {\"svr__C\": [1e0, 1e1, 1e2, 1e3,1e4,1e6],'svr__kernel':['linear','poly', 'rbf', 'sigmoid']}\n",
    "    support_vector_regressor_model = create_gridsearch_model(support_vector_regressor_hyperparameters,X_train,y_train, regressor=SVR())\n",
    "    print(support_vector_regressor_model.score(X_test, y_test))\n",
    "    print(\"SVR\",support_vector_regressor_model.best_params_)\n",
    "    dump(support_vector_regressor_model, 'svr.joblib')\n",
    "    #=======================================\n",
    "    #\n",
    "    # Linear regression\n",
    "    #\n",
    "    #=======================================\n",
    "    linear_regression_model = LinearRegression().fit(X_train, y_train)\n",
    "    linear_score = linear_regression_model.score(X_test, y_test)\n",
    "    dump(linear_regression_model, 'linear.joblib')\n",
    "    print(\"LR\",linear_score)\n",
    "    #=======================================\n",
    "    #\n",
    "    # XGBoost\n",
    "    #\n",
    "    #=======================================\n",
    "    xgb_hyperparameters = {\"xgbregressor__learning_rate\"    : [0.0001, 0.001, 0.01, 0.1, 1.0] ,\n",
    " \"xgbregressor__max_depth\"        : [1,5,10,'None'],\n",
    " \"xgbregressor__min_child_weight\" : [0,1,5,10,20,50],\n",
    " \"xgbregressor__gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    " \"xgbregressor__subsample\" : [ 0.5 , 0.7 ,0.9,1.0] }\n",
    "    xgb_regressor_model = create_gridsearch_model(xgb_hyperparameters, X_train, y_train, regressor=XGBRegressor())\n",
    "    print(xgb_regressor_model.best_params_)\n",
    "    print(\"XGB\",xgb_regressor_model.score(X_test,y_test))\n",
    "    dump(xgb_regressor_model, 'xgb.joblib')\n",
    "handler(1,2)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'randomforestregressor__max_depth': 10, 'randomforestregressor__max_features': 3, 'randomforestregressor__max_samples': 100, 'randomforestregressor__n_estimators': 1000}\n",
      "RF 0.8356344126226198\n",
      "0.8921572491120295\n",
      "SVR {'svr__C': 10.0, 'svr__kernel': 'linear'}\n",
      "LR 0.8912193365936915\n",
      "{'xgbregressor__gamma': 0.2, 'xgbregressor__learning_rate': 0.1, 'xgbregressor__max_depth': 5, 'xgbregressor__min_child_weight': 5, 'xgbregressor__subsample': 1.0}\n",
      "XGB 0.8342095142062582\n"
     ]
    }
   ]
  }
 ]
}